{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Heartbeat Classification: Training Notebook  \n",
    "In this notebook you will find instructions to proceed with the python scripts for training the models on your own hardware to reproduce the models we implemented "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparation    \n",
    "In this step you will prepare the environment and a YAML file of all paths of models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\r\n",
      "  MITBIH: /home/ander/Documents/git/mlfhc/visualization_clustering/baseline_cnn_mitbih.h5\r\n",
      "  MITBIH_Representation: /home/ander/Documents/git/mlfhc/visualization_clustering/mitbih_representations.npy\r\n",
      "  PTDB: /home/ander/Documents/git/mlfhc/visualization_clustering/baseline_cnn_ptbdb.h5\r\n",
      "  PTDB_Representation: /home/ander/Documents/git/mlfhc/visualization_clustering/ptbdb_representations.npy\r\n",
      "MITBIH:\r\n",
      "  Data: /home/ander/Documents/git/mlfhc/data\r\n",
      "  Models:\r\n",
      "    BRNN: /home/ander/Documents/git/mlfhc/models/brnn/brnn_mitbih.h5\r\n",
      "    CNN_LSTM: /home/ander/Documents/git/mlfhc/models/cnn_lstm/best_clfc_mitbih_9801.h5\r\n",
      "    CNN_Res: /home/ander/Documents/git/mlfhc/models/cnn_res/cnn_residual_mitbih.h5\r\n",
      "    GRU: /home/ander/Documents/git/mlfhc/models/gru/best_model_GRU_mitbih_9817.h5\r\n",
      "    Inception: /home/ander/Documents/git/mlfhc/models/inception/BestModel_Inception_mitbih_9891.h5\r\n",
      "    LSTM: /home/ander/Documents/git/mlfhc/models/lstm/best_model_lstm_mitbih_976.h5\r\n",
      "    RNN: /home/ander/Documents/git/mlfhc/models/rnn/BestModel_RNN_mitbih_908.h5\r\n",
      "Optionals:\r\n",
      "  Optional_1:\r\n",
      "    Optional1_GRU: /home/ander/Documents/git/mlfhc/optionals/optional1/optional1_GRU.h5\r\n",
      "    Optional1_LSTM: /home/ander/Documents/git/mlfhc/optionals/optional1/optional1_LSTM.h5\r\n",
      "    Optional1_RNN: /home/ander/Documents/git/mlfhc/optionals/optional1/optional1_RNN.h5\r\n",
      "  Optional_2:\r\n",
      "    Optional2_GRU: /home/ander/Documents/git/mlfhc/optionals/optional2/optional2_GRU.h5\r\n",
      "    Optional2_LSTM: /home/ander/Documents/git/mlfhc/optionals/optional2/optional2_LSTM.h5\r\n",
      "    Optional2_RNN: /home/ander/Documents/git/mlfhc/optionals/optional2/optional2_RNN.h5\r\n",
      "  Optional_3:\r\n",
      "    Optional3_GRU: /home/ander/Documents/git/mlfhc/optionals/optional3/optional3_GRU.h5\r\n",
      "    Optional3_LSTM: /home/ander/Documents/git/mlfhc/optionals/optional3/optional3_LSTM.h5\r\n",
      "    Optional3_RNN: /home/ander/Documents/git/mlfhc/optionals/optional3/optional3_RNN.h5\r\n",
      "PTDB:\r\n",
      "  Data: /home/ander/Documents/git/mlfhc/data\r\n",
      "  Models:\r\n",
      "    BRNN: /home/ander/Documents/git/mlfhc/models/brnn/brnn_ptbdb.h5\r\n",
      "    CNN_LSTM: /home/ander/Documents/git/mlfhc/models/cnn_lstm/best_clf_ptbdb_9776_2cnn.h5\r\n",
      "    CNN_Res: /home/ander/Documents/git/mlfhc/models/cnn_res/cnn_residual_ptbdb.h5\r\n",
      "    GRU: /home/ander/Documents/git/mlfhc/models/gru/BestModel_GRU_ptdb_9014.h5\r\n",
      "    Inception: /home/ander/Documents/git/mlfhc/models/inception/BestModel_Inception_ptdb_7220.h5\r\n",
      "    LSTM: /home/ander/Documents/git/mlfhc/models/lstm/best_model_lstm_ptbdb_9673.h5\r\n",
      "    RNN: /home/ander/Documents/git/mlfhc/models/rnn/BestModel_RNN_ptdb_91.h5\r\n"
     ]
    }
   ],
   "source": [
    "%run write_yaml.py\n",
    "!cat paths.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Recurrent Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for PTBDB dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (11641, 187, 1)\n",
      "Y shape:  (11641,)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_22 (SimpleRNN)    (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 187, 64)           256       \n",
      "_________________________________________________________________\n",
      "simple_rnn_23 (SimpleRNN)    (None, 187, 64)           8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 187, 64)           256       \n",
      "_________________________________________________________________\n",
      "simple_rnn_24 (SimpleRNN)    (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 43,649\n",
      "Trainable params: 42,625\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      "10476/10476 [==============================] - 16s 2ms/step - loss: 0.6411 - acc: 0.6584 - val_loss: 0.6733 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/models/rnn/RNN_ptdb.h5\n",
      "Test accuracy score : 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run models/rnn/RNN_ptdb.py --epoch 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for MITBIH Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_25 (SimpleRNN)    (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "simple_rnn_26 (SimpleRNN)    (None, 187, 64)           8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_27 (SimpleRNN)    (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 29,381\n",
      "Trainable params: 29,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/1\n",
      "78798/78798 [==============================] - 103s 1ms/step - loss: 0.6621 - acc: 0.8257 - val_loss: 0.6725 - val_acc: 0.8259\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.82595, saving model to /home/ander/Documents/git/mlfhc/models/rnn/RNN_mitbih.h5\n",
      "Test accuracy score : 0.8276082587246483 \n"
     ]
    }
   ],
   "source": [
    "%run models/rnn/RNN_mitbih.py --epoch 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Long Short Term Memory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for MITBIH Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (87554, 187, 1)\n",
      "Y shape:  (87554, 5)\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 187, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 187, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 91,589\n",
      "Trainable params: 91,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/1\n",
      "78798/78798 [==============================] - 287s 4ms/step - loss: 0.6672 - acc: 0.8274 - val_loss: 0.6690 - val_acc: 0.8259\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.82595, saving model to /home/ander/Documents/git/mlfhc/models/lstm/LSTM_mitbih.h5\n",
      "(21892, 187, 1)\n",
      "(21892, 5)\n",
      "Test accuracy score : 0.8276082587246483 \n"
     ]
    }
   ],
   "source": [
    "%run models/lstm/lstm_mitbih.py --epoch 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for PTBDB dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 187, 64)           16896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 187, 64)           256       \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 187, 64)           33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 187, 64)           256       \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 101,441\n",
      "Trainable params: 100,545\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      "10476/10476 [==============================] - 42s 4ms/step - loss: 0.6215 - acc: 0.7038 - val_loss: 0.6162 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/models/lstm/LSTM_ptdb.h5\n",
      "Test accuracy score : 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run models/lstm/lstm_ptbdb.py --epoch 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Gated Recurrent Unit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for MITBIH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 187, 64)           24768     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 70,853\n",
      "Trainable params: 70,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/1\n",
      "78798/78798 [==============================] - 268s 3ms/step - loss: 0.5534 - acc: 0.8514 - val_loss: 0.3481 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89870, saving model to /home/ander/Documents/git/mlfhc/models/gru/GRU_mitbih.h5\n",
      "Test accuracy score : 0.9024757902430112 \n"
     ]
    }
   ],
   "source": [
    "%run models/gru/GRU_mitbih.py --epoch 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for PTBDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 187, 64)           256       \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 187, 64)           24768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 187, 64)           256       \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 70,417\n",
      "Trainable params: 69,785\n",
      "Non-trainable params: 632\n",
      "_________________________________________________________________\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      "10476/10476 [==============================] - 41s 4ms/step - loss: 0.6262 - acc: 0.6784 - val_loss: 0.6113 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/models/gru/GRU_ptdb.h5\n",
      "Test accuracy score : 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run models/gru/GRU_ptdb.py --epoch 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Convolutional Neural Network based Models\n",
    "#### 2.4.1. CNN with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for MITBIH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 187, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 187, 16)           64        \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 187, 32)           1568      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 93, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 93, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 93, 64)            6208      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 93, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 46, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 46, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 46, 256)           98560     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 23, 32)            36992     \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 23, 32)            128       \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3_mitbih (Dense)       (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 183,269\n",
      "Trainable params: 183,141\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/1\n",
      " - 63s - loss: 0.3190 - acc: 0.9068 - val_loss: 0.1915 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94689, saving model to /home/ander/Documents/git/mlfhc/models/cnn_lstm/CNN_LSTM_mitbih.h5\n",
      "Test accuracy score : 0.9464644619038919 \n"
     ]
    }
   ],
   "source": [
    "%run models/cnn_lstm/cnn_lstm_fc_mitbih.py --epoch 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for PTBDB dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 187, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 187, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 187, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 93, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 93, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 93, 32)            12416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 93, 32)            128       \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3_mitbih (Dense)       (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 31,585\n",
      "Trainable params: 31,457\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 17s - loss: 0.5551 - acc: 0.7227 - val_loss: 0.6537 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/models/cnn_lstm/CNN_LSTM_ptdb.h5\n",
      "Test accuracy score : 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run models/cnn_lstm/cnn_lstm_fc_ptbdb.py --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2. CNN with Residual Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for MITBIH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 187, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 183, 16)      96          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 179, 16)      1296        conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 89, 16)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 89, 16)       0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 87, 32)       1568        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 85, 32)       3104        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 42, 32)       0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 42, 32)       0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 40, 32)       3104        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 38, 32)       3104        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 19, 32)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 19, 32)       0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 17, 256)      24832       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 15, 256)      196864      conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 185, 256)     1024        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 256)          0           global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 256)          0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256)          0           dropout_8[0][0]                  \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_mitbih (Dense)          (None, 5)            325         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 255,925\n",
      "Trainable params: 255,925\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.3124 - acc: 0.9133 - val_loss: 0.1728 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95055, saving model to /home/ander/Documents/git/mlfhc/models/cnn_res/CNN_RES_mitbih.h5\n",
      "Test f1 score : 0.6657238459484608 \n",
      "Test accuracy score : 0.9525854193312625 \n"
     ]
    }
   ],
   "source": [
    "%run models/cnn_res/cnn_residual_mitbih.py --epoch 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training for PTBDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 187, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 183, 16)      96          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 179, 16)      1296        conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 89, 16)       0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 89, 16)       0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 87, 32)       1568        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 85, 32)       3104        conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 42, 32)       0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 42, 32)       0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 40, 32)       3104        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 38, 32)       3104        conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 19, 32)       0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 19, 32)       0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 17, 256)      24832       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 15, 256)      196864      conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 256)          0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 185, 256)     1024        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 256)          0           global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 256)          0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256)          0           dropout_16[0][0]                 \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_ptbdb (Dense)           (None, 1)            65          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 255,665\n",
      "Trainable params: 255,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.5228 - acc: 0.7352 - val_loss: 0.4724 - val_acc: 0.7554\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75536, saving model to /home/ander/Documents/git/mlfhc/models/cnn_res/CNN_RES_ptdb.h5\n",
      "Test f1 score : 0.8669783255418615 \n",
      "Test accuracy score : 0.7849536241841292 \n"
     ]
    }
   ],
   "source": [
    "%run models/cnn_res/cnn_residual_ptbdb.py --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Inception Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for MITBIH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (87554, 187, 1)\n",
      "Y shape:  (87554, 5)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 187, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 178, 32)      320         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 169, 32)      10240       conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 169, 32)      1024        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 169, 32)      10240       conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 169, 32)      20480       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 169, 32)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 169, 32)      40960       conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 169, 32)      1024        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 169, 128)     0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 169, 128)     512         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu (TensorFlowOpL [(None, 169, 128)]   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 169, 32)      4096        tf_op_layer_Relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 169, 32)      10240       conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 169, 32)      20480       conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 169, 128)     0           tf_op_layer_Relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 169, 32)      40960       conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 169, 32)      4096        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 169, 128)     0           conv1d_8[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 169, 128)     512         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_1 (TensorFlowO [(None, 169, 128)]   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 169, 32)      4096        tf_op_layer_Relu_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 169, 32)      10240       conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 169, 32)      20480       conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 169, 128)     0           tf_op_layer_Relu_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 169, 32)      40960       conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 169, 32)      4096        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 169, 128)     0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 169, 128)     4096        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 169, 128)     512         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 169, 128)     512         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_2 (TensorFlowO [(None, 169, 128)]   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 169, 128)     0           batch_normalization_3[0][0]      \n",
      "                                                                 tf_op_layer_Relu_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5)            645         global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 250,821\n",
      "Trainable params: 249,797\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Train on 78798 samples, validate on 8756 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78784/78798 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9550\n",
      "Epoch 00001: val_acc improved from -inf to 0.96265, saving model to /home/ander/Documents/git/mlfhc/models/inception/INCEPTION_mitbih.h5\n",
      "78798/78798 [==============================] - 255s 3ms/sample - loss: 0.1701 - acc: 0.9550 - val_loss: 0.1401 - val_acc: 0.9627\n",
      "Test accuracy score : 0.9619038918326329 \n"
     ]
    }
   ],
   "source": [
    "%run models/inception/inception_mitbih.py --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for PTBDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (11641, 187, 1)\n",
      "Y shape:  (11641,)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 187, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 178, 32)      320         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 169, 32)      10240       conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 169, 32)      1024        conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 169, 32)      10240       conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 169, 32)      20480       conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 169, 32)      0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 169, 32)      40960       conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 169, 32)      1024        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 169, 128)     0           conv1d_21[0][0]                  \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 169, 128)     512         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_3 (TensorFlowO [(None, 169, 128)]   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 169, 32)      4096        tf_op_layer_Relu_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 169, 32)      10240       conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 169, 32)      20480       conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 169, 128)     0           tf_op_layer_Relu_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 169, 32)      40960       conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 169, 32)      4096        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 169, 128)     0           conv1d_26[0][0]                  \n",
      "                                                                 conv1d_27[0][0]                  \n",
      "                                                                 conv1d_28[0][0]                  \n",
      "                                                                 conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 169, 128)     512         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_4 (TensorFlowO [(None, 169, 128)]   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 169, 32)      4096        tf_op_layer_Relu_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 169, 32)      10240       conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 169, 32)      20480       conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 169, 128)     0           tf_op_layer_Relu_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 169, 32)      40960       conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 169, 32)      4096        max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 169, 128)     0           conv1d_31[0][0]                  \n",
      "                                                                 conv1d_32[0][0]                  \n",
      "                                                                 conv1d_33[0][0]                  \n",
      "                                                                 conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 169, 128)     4096        conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 169, 128)     512         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 169, 128)     512         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_5 (TensorFlowO [(None, 169, 128)]   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 169, 128)     0           batch_normalization_7[0][0]      \n",
      "                                                                 tf_op_layer_Relu_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         global_average_pooling1d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 250,305\n",
      "Trainable params: 249,281\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Train on 10476 samples, validate on 1165 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10432/10476 [============================>.] - ETA: 0s - loss: 4.2070 - acc: 0.7241\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/models/inception/INCEPTION_ptdb.h5\n",
      "10476/10476 [==============================] - 32s 3ms/sample - loss: 4.2024 - acc: 0.7244 - val_loss: 4.5813 - val_acc: 0.6996\n",
      "Test accuracy score : 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run models/inception/inception_ptdb.py --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Bidirectional Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for MITBIH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 187, 128)          8448      \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 187, 128)          24704     \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 70,597\n",
      "Trainable params: 70,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/1\n",
      "78798/78798 [==============================] - 164s 2ms/step - loss: 0.2741 - acc: 0.9272 - val_loss: 0.2126 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95009, saving model to /home/ander/Documents/git/mlfhc/models/brnn/BRNN_mitbih.h5\n",
      "Test accuracy score : 0.9487027224556915 \n"
     ]
    }
   ],
   "source": [
    "%run models/brnn/BRNN_mitbih.py --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for PTBDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_4 (Bidirection (None, 187, 128)          8448      \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 187, 128)          512       \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 187, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 187, 128)          512       \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 85,633\n",
      "Trainable params: 84,225\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      "10476/10476 [==============================] - 26s 2ms/step - loss: 0.4904 - acc: 0.7760 - val_loss: 0.6285 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/models/brnn/BRNN_ptdb.h5\n",
      "Test accuracy score : 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run models/brnn/BRNN_ptbdb.py --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8. Transfer Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8.1. Optional 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model : /home/ander/Documents/git/mlfhc/models/gru/GRU_mitbih.h5\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 187, 64)           24768     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 70,853\n",
      "Trainable params: 70,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 187, 64)           24768     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                24768     \n",
      "=================================================================\n",
      "Total params: 62,208\n",
      "Trainable params: 62,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_77 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,729\n",
      "Trainable params: 17,217\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Best model will be saved in  OPT1_GRU.h5\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5422 - acc: 0.7138 - val_loss: 0.5618 - val_acc: 0.6884\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.68841, saving model to /home/ander/Documents/git/mlfhc/optionals/optional1/OPT1_GRU.h5\n",
      "Test accuracy score : 0.7110958433527997 \n"
     ]
    }
   ],
   "source": [
    "%run optionals/optional1/optional1.py --model GRU --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for RNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model : /home/ander/Documents/git/mlfhc/models/rnn/RNN_mitbih.h5\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_25 (SimpleRNN)    (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "simple_rnn_26 (SimpleRNN)    (None, 187, 64)           8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_27 (SimpleRNN)    (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 29,381\n",
      "Trainable params: 29,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_25 (SimpleRNN)    (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "simple_rnn_26 (SimpleRNN)    (None, 187, 64)           8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_27 (SimpleRNN)    (None, 64)                8256      \n",
      "=================================================================\n",
      "Total params: 20,736\n",
      "Trainable params: 20,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_82 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,729\n",
      "Trainable params: 17,217\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Best model will be saved in  OPT1_RNN.h5\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6255 - acc: 0.7270 - val_loss: 0.6165 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/optionals/optional1/OPT1_RNN.h5\n",
      "Test accuracy score : 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run optionals/optional1/optional1.py --model RNN --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model : /home/ander/Documents/git/mlfhc/models/lstm/LSTM_mitbih.h5\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 187, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 187, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 91,589\n",
      "Trainable params: 91,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 187, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 187, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "=================================================================\n",
      "Total params: 82,944\n",
      "Trainable params: 82,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,729\n",
      "Trainable params: 17,217\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Best model will be saved in  OPT1_LSTM.h5\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5890 - acc: 0.7147 - val_loss: 0.6346 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/optionals/optional1/OPT1_LSTM.h5\n",
      "Test accuracy score : 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run optionals/optional1/optional1.py --model LSTM --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8.2. Optional 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model : /home/ander/Documents/git/mlfhc/models/gru/GRU_mitbih.h5\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 187, 64)           24768     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 70,853\n",
      "Trainable params: 70,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 187, 64)           24768     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                24768     \n",
      "=================================================================\n",
      "Total params: 62,208\n",
      "Trainable params: 62,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 187, 64)           24768     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 79,937\n",
      "Trainable params: 79,425\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Best model will be saved in  OPT2_GRU.h5\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.5080 - acc: 0.7442 - val_loss: 0.5866 - val_acc: 0.7966\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79657, saving model to /home/ander/Documents/git/mlfhc/optionals/optional2/OPT2_GRU.h5\n",
      "Test accuracy score : 0.7990381312263827 \n"
     ]
    }
   ],
   "source": [
    "%run optionals/optional2/optional2.py --model GRU --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model : /home/ander/Documents/git/mlfhc/models/rnn/RNN_mitbih.h5\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_25 (SimpleRNN)    (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "simple_rnn_26 (SimpleRNN)    (None, 187, 64)           8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_27 (SimpleRNN)    (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 29,381\n",
      "Trainable params: 29,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_25 (SimpleRNN)    (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "simple_rnn_26 (SimpleRNN)    (None, 187, 64)           8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_27 (SimpleRNN)    (None, 64)                8256      \n",
      "=================================================================\n",
      "Total params: 20,736\n",
      "Trainable params: 20,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_25 (SimpleRNN)    (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "simple_rnn_26 (SimpleRNN)    (None, 187, 64)           8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_27 (SimpleRNN)    (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 38,465\n",
      "Trainable params: 37,953\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Best model will be saved in  OPT2_RNN.h5\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 14s - loss: 0.6331 - acc: 0.7146 - val_loss: 0.6678 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/optionals/optional2/OPT2_RNN.h5\n",
      "Test accuracy score : 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run optionals/optional2/optional2.py --model RNN --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model : /home/ander/Documents/git/mlfhc/models/lstm/LSTM_mitbih.h5\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 187, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 187, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 91,589\n",
      "Trainable params: 91,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 187, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 187, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "=================================================================\n",
      "Total params: 82,944\n",
      "Trainable params: 82,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 187, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 187, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 100,673\n",
      "Trainable params: 100,161\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Best model will be saved in  OPT2_LSTM.h5\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.5845 - acc: 0.7065 - val_loss: 0.6404 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/optionals/optional2/OPT2_LSTM.h5\n",
      "Test accuracy score : 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run optionals/optional2/optional2.py --model LSTM --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8.3. Optional 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Loading Model : /home/ander/Documents/git/mlfhc/models/gru/GRU_mitbih.h5\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 187, 64)           24768     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 70,853\n",
      "Trainable params: 70,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 187, 64)           24768     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                24768     \n",
      "=================================================================\n",
      "Total params: 62,208\n",
      "Trainable params: 62,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Summary after adding fc layers and freezing layers from base model\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 187, 64)           24768     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 79,937\n",
      "Trainable params: 17,217\n",
      "Non-trainable params: 62,720\n",
      "_________________________________________________________________\n",
      "Best model will be saved in  OPT3_GRU.h5\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.5310 - acc: 0.7269 - val_loss: 0.5987 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/optionals/optional3/OPT3_GRU.h5\n",
      "Test accuracy score with frozen first layers : 0.7220886293369976 \n",
      "Model Summary after unfreezing layers\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 187, 64)           24768     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 79,937\n",
      "Trainable params: 79,425\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.4042 - acc: 0.8142 - val_loss: 0.3883 - val_acc: 0.8386\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.69957 to 0.83863, saving model to /home/ander/Documents/git/mlfhc/optionals/optional3/OPT3_GRU.h5\n",
      "Test accuracy score after unfreezing and training whole model: 0.8419787014771556 \n"
     ]
    }
   ],
   "source": [
    "%run optionals/optional3/optional3.py --model GRU --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Loading Model : /home/ander/Documents/git/mlfhc/models/rnn/RNN_mitbih.h5\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_25 (SimpleRNN)    (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "simple_rnn_26 (SimpleRNN)    (None, 187, 64)           8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_27 (SimpleRNN)    (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 29,381\n",
      "Trainable params: 29,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_25 (SimpleRNN)    (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "simple_rnn_26 (SimpleRNN)    (None, 187, 64)           8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_27 (SimpleRNN)    (None, 64)                8256      \n",
      "=================================================================\n",
      "Total params: 20,736\n",
      "Trainable params: 20,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Summary after adding fc layers and freezing layers from base model\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_25 (SimpleRNN)    (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "simple_rnn_26 (SimpleRNN)    (None, 187, 64)           8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_27 (SimpleRNN)    (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 38,465\n",
      "Trainable params: 17,217\n",
      "Non-trainable params: 21,248\n",
      "_________________________________________________________________\n",
      "Best model will be saved in  OPT3_RNN.h5\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.6333 - acc: 0.7225 - val_loss: 0.6120 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/optionals/optional3/OPT3_RNN.h5\n",
      "Test accuracy score with frozen first layers : 0.7220886293369976 \n",
      "Model Summary after unfreezing layers\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_25 (SimpleRNN)    (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "simple_rnn_26 (SimpleRNN)    (None, 187, 64)           8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_27 (SimpleRNN)    (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 38,465\n",
      "Trainable params: 37,953\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 14s - loss: 0.5988 - acc: 0.7221 - val_loss: 5.2461 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.69957\n",
      "Test accuracy score after unfreezing and training whole model: 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run optionals/optional3/optional3.py --model RNN --epoch 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Loading Model : /home/ander/Documents/git/mlfhc/models/lstm/LSTM_mitbih.h5\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 187, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 187, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 91,589\n",
      "Trainable params: 91,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 187, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 187, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "=================================================================\n",
      "Total params: 82,944\n",
      "Trainable params: 82,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Summary after adding fc layers and freezing layers from base model\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 187, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 187, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 100,673\n",
      "Trainable params: 17,217\n",
      "Non-trainable params: 83,456\n",
      "_________________________________________________________________\n",
      "Best model will be saved in  OPT3_LSTM.h5\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.5928 - acc: 0.7111 - val_loss: 0.7447 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to /home/ander/Documents/git/mlfhc/optionals/optional3/OPT3_LSTM.h5\n",
      "Test accuracy score with frozen first layers : 0.7220886293369976 \n",
      "Model Summary after unfreezing layers\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 187, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 187, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 100,673\n",
      "Trainable params: 100,161\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.5702 - acc: 0.7214 - val_loss: 5.5184 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.69957\n",
      "Test accuracy score after unfreezing and training whole model: 0.7220886293369976 \n"
     ]
    }
   ],
   "source": [
    "%run optionals/optional3/optional3.py --model LSTM --epoch 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
