Sender: LSF System <lsfadmin@lo-s4-015>
Subject: Job 5241967: <python optionals/optional3/optional3.py --model RNN> in cluster <leonhard> Done

Job <python optionals/optional3/optional3.py --model RNN> was submitted from host <lo-login-01> by user <bberabi> in cluster <leonhard> at Tue Mar 17 03:31:08 2020
Job was executed on host(s) <2*lo-s4-015>, in queue <normal.24h>, as user <bberabi> in cluster <leonhard> at Tue Mar 17 03:31:36 2020
</cluster/home/bberabi> was used as the home directory.
</cluster/home/bberabi/mlfhc> was used as the working directory.
Started at Tue Mar 17 03:31:36 2020
Terminated at Tue Mar 17 03:38:49 2020
Results reported at Tue Mar 17 03:38:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python optionals/optional3/optional3.py --model RNN
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1300.53 sec.
    Max Memory :                                 1099 MB
    Average Memory :                             969.88 MB
    Total Requested Memory :                     4000.00 MB
    Delta Memory :                               2901.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   458 sec.
    Turnaround time :                            461 sec.

The output (if any) follows:

2020-03-17 03:31:46.316344: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-03-17 03:31:46.331107: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199850000 Hz
2020-03-17 03:31:46.331557: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x510aac0 executing computations on platform Host. Devices:
2020-03-17 03:31:46.331596: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
----------------------------------------------
Loading Model : /cluster/home/bberabi/mlfhc/models/rnn/BestModel_RNN_mitbih_908.h5
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 187, 64)           4224      
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, 187, 64)           8256      
_________________________________________________________________
simple_rnn_3 (SimpleRNN)     (None, 64)                8256      
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 325       
=================================================================
Total params: 29,381
Trainable params: 29,381
Non-trainable params: 0
_________________________________________________________________
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 187, 64)           4224      
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, 187, 64)           8256      
_________________________________________________________________
simple_rnn_3 (SimpleRNN)     (None, 64)                8256      
=================================================================
Total params: 20,736
Trainable params: 20,736
Non-trainable params: 0
_________________________________________________________________
Model Summary after adding fc layers and freezing layers from base model
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 187, 64)           4224      
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, 187, 64)           8256      
_________________________________________________________________
simple_rnn_3 (SimpleRNN)     (None, 64)                8256      
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_1 (Batch (None, 64)                256       
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
dense_3 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_3 (Batch (None, 64)                256       
_________________________________________________________________
dense_4 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 65        
=================================================================
Total params: 38,465
Trainable params: 17,217
Non-trainable params: 21,248
_________________________________________________________________
Best model will be saved in  optional3_RNN.h5
Train on 10476 samples, validate on 1165 samples
Epoch 1/100
 - 8s - loss: 0.5763 - acc: 0.6767 - val_loss: 0.5864 - val_acc: 0.6996

Epoch 00001: val_acc improved from -inf to 0.69957, saving model to optional3_RNN.h5
Epoch 2/100
 - 7s - loss: 0.5221 - acc: 0.7213 - val_loss: 0.5357 - val_acc: 0.6996

Epoch 00002: val_acc did not improve from 0.69957
Epoch 3/100
 - 7s - loss: 0.5200 - acc: 0.7197 - val_loss: 0.5318 - val_acc: 0.7004

Epoch 00003: val_acc improved from 0.69957 to 0.70043, saving model to optional3_RNN.h5
Epoch 4/100
 - 7s - loss: 0.5194 - acc: 0.7206 - val_loss: 0.5421 - val_acc: 0.7021

Epoch 00004: val_acc improved from 0.70043 to 0.70215, saving model to optional3_RNN.h5
Epoch 5/100
 - 7s - loss: 0.5188 - acc: 0.7229 - val_loss: 0.5325 - val_acc: 0.7082

Epoch 00005: val_acc improved from 0.70215 to 0.70815, saving model to optional3_RNN.h5
Epoch 6/100
 - 7s - loss: 0.5185 - acc: 0.7240 - val_loss: 0.5387 - val_acc: 0.7142

Epoch 00006: val_acc improved from 0.70815 to 0.71416, saving model to optional3_RNN.h5
Epoch 7/100
 - 7s - loss: 0.5181 - acc: 0.7214 - val_loss: 0.5334 - val_acc: 0.7013

Epoch 00007: val_acc did not improve from 0.71416
Epoch 8/100
 - 7s - loss: 0.5164 - acc: 0.7247 - val_loss: 0.5326 - val_acc: 0.7030

Epoch 00008: val_acc did not improve from 0.71416
Epoch 9/100
 - 7s - loss: 0.5166 - acc: 0.7232 - val_loss: 0.5340 - val_acc: 0.7167

Epoch 00009: val_acc improved from 0.71416 to 0.71674, saving model to optional3_RNN.h5
Epoch 10/100
 - 7s - loss: 0.5163 - acc: 0.7210 - val_loss: 0.5308 - val_acc: 0.7004

Epoch 00010: val_acc did not improve from 0.71674
Epoch 11/100
 - 7s - loss: 0.5150 - acc: 0.7266 - val_loss: 0.5414 - val_acc: 0.6987

Epoch 00011: val_acc did not improve from 0.71674
Epoch 12/100
 - 7s - loss: 0.5157 - acc: 0.7265 - val_loss: 0.5300 - val_acc: 0.7124

Epoch 00012: val_acc did not improve from 0.71674
Epoch 13/100
 - 7s - loss: 0.5165 - acc: 0.7245 - val_loss: 0.5294 - val_acc: 0.7107

Epoch 00013: val_acc did not improve from 0.71674
Epoch 14/100
 - 7s - loss: 0.5174 - acc: 0.7252 - val_loss: 0.5367 - val_acc: 0.7082

Epoch 00014: val_acc did not improve from 0.71674
Epoch 15/100
 - 7s - loss: 0.5147 - acc: 0.7255 - val_loss: 0.5393 - val_acc: 0.7064

Epoch 00015: val_acc did not improve from 0.71674
Epoch 16/100
 - 7s - loss: 0.5158 - acc: 0.7272 - val_loss: 0.5307 - val_acc: 0.7064

Epoch 00016: val_acc did not improve from 0.71674

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 17/100
 - 7s - loss: 0.5150 - acc: 0.7264 - val_loss: 0.5368 - val_acc: 0.6987

Epoch 00017: val_acc did not improve from 0.71674
Epoch 18/100
 - 7s - loss: 0.5160 - acc: 0.7264 - val_loss: 0.5311 - val_acc: 0.7082

Epoch 00018: val_acc did not improve from 0.71674
Epoch 19/100
 - 7s - loss: 0.5140 - acc: 0.7281 - val_loss: 0.5342 - val_acc: 0.7047

Epoch 00019: val_acc did not improve from 0.71674
Epoch 00019: early stopping
Test accuracy score with frozen first layers : 0.7217451047749914 
Model Summary after unfreezing layers
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 187, 64)           4224      
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, 187, 64)           8256      
_________________________________________________________________
simple_rnn_3 (SimpleRNN)     (None, 64)                8256      
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_1 (Batch (None, 64)                256       
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
dense_3 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_3 (Batch (None, 64)                256       
_________________________________________________________________
dense_4 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 65        
=================================================================
Total params: 38,465
Trainable params: 37,953
Non-trainable params: 512
_________________________________________________________________
Train on 10476 samples, validate on 1165 samples
Epoch 1/100
 - 22s - loss: 0.6130 - acc: 0.7133 - val_loss: 0.7469 - val_acc: 0.3013

Epoch 00001: val_acc did not improve from 0.71674
Epoch 2/100
 - 20s - loss: 0.5996 - acc: 0.7203 - val_loss: 0.6791 - val_acc: 0.6996

Epoch 00002: val_acc did not improve from 0.71674
Epoch 3/100
 - 20s - loss: 0.5950 - acc: 0.7230 - val_loss: 0.9512 - val_acc: 0.6996

Epoch 00003: val_acc did not improve from 0.71674
Epoch 4/100
 - 20s - loss: 0.5909 - acc: 0.7240 - val_loss: 4.2832 - val_acc: 0.6996

Epoch 00004: val_acc did not improve from 0.71674
Epoch 5/100
 - 20s - loss: 0.5897 - acc: 0.7241 - val_loss: 0.6455 - val_acc: 0.6464

Epoch 00005: val_acc did not improve from 0.71674
Epoch 6/100
 - 20s - loss: 0.5893 - acc: 0.7235 - val_loss: 1.0128 - val_acc: 0.6996

Epoch 00006: val_acc did not improve from 0.71674
Epoch 7/100
 - 20s - loss: 0.5882 - acc: 0.7238 - val_loss: 2.0862 - val_acc: 0.6996

Epoch 00007: val_acc did not improve from 0.71674
Epoch 8/100
 - 20s - loss: 0.5819 - acc: 0.7242 - val_loss: 24.8875 - val_acc: 0.6996

Epoch 00008: val_acc did not improve from 0.71674
Epoch 9/100
 - 20s - loss: 0.5752 - acc: 0.7261 - val_loss: 52.8264 - val_acc: 0.6996

Epoch 00009: val_acc did not improve from 0.71674

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 10/100
 - 20s - loss: 0.5711 - acc: 0.7262 - val_loss: 17.4443 - val_acc: 0.6996

Epoch 00010: val_acc did not improve from 0.71674
Epoch 11/100
 - 20s - loss: 0.5665 - acc: 0.7285 - val_loss: 11.4426 - val_acc: 0.6996

Epoch 00011: val_acc did not improve from 0.71674
Epoch 12/100
 - 20s - loss: 0.5583 - acc: 0.7250 - val_loss: 46.0533 - val_acc: 0.6996
Using TensorFlow backend.

Epoch 00012: val_acc did not improve from 0.71674
Epoch 00012: early stopping
Test accuracy score after unfreezing and training whole model: 0.7220886293369976 
