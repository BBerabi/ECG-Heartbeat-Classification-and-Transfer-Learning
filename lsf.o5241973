Sender: LSF System <lsfadmin@lo-a2-071>
Subject: Job 5241973: <python optionals/optional3/optional3.py --model LSTM> in cluster <leonhard> Done

Job <python optionals/optional3/optional3.py --model LSTM> was submitted from host <lo-login-01> by user <bberabi> in cluster <leonhard> at Tue Mar 17 03:35:09 2020
Job was executed on host(s) <2*lo-a2-071>, in queue <normal.24h>, as user <bberabi> in cluster <leonhard> at Tue Mar 17 03:35:36 2020
</cluster/home/bberabi> was used as the home directory.
</cluster/home/bberabi/mlfhc> was used as the working directory.
Started at Tue Mar 17 03:35:36 2020
Terminated at Tue Mar 17 05:24:57 2020
Results reported at Tue Mar 17 05:24:57 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python optionals/optional3/optional3.py --model LSTM
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22184.88 sec.
    Max Memory :                                 1204 MB
    Average Memory :                             1084.63 MB
    Total Requested Memory :                     4000.00 MB
    Delta Memory :                               2796.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   6587 sec.
    Turnaround time :                            6588 sec.

The output (if any) follows:

2020-03-17 03:35:42.017236: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-03-17 03:35:42.025026: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2020-03-17 03:35:42.025402: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b935d0 executing computations on platform Host. Devices:
2020-03-17 03:35:42.025431: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
----------------------------------------------
Loading Model : /cluster/home/bberabi/mlfhc/models/lstm/best_model_lstm_mitbih_976.h5
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 187, 64)           16896     
_________________________________________________________________
lstm_2 (LSTM)                (None, 187, 64)           33024     
_________________________________________________________________
lstm_3 (LSTM)                (None, 64)                33024     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 325       
=================================================================
Total params: 91,589
Trainable params: 91,589
Non-trainable params: 0
_________________________________________________________________
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 187, 64)           16896     
_________________________________________________________________
lstm_2 (LSTM)                (None, 187, 64)           33024     
_________________________________________________________________
lstm_3 (LSTM)                (None, 64)                33024     
=================================================================
Total params: 82,944
Trainable params: 82,944
Non-trainable params: 0
_________________________________________________________________
Model Summary after adding fc layers and freezing layers from base model
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 187, 64)           16896     
_________________________________________________________________
lstm_2 (LSTM)                (None, 187, 64)           33024     
_________________________________________________________________
lstm_3 (LSTM)                (None, 64)                33024     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_1 (Batch (None, 64)                256       
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
dense_3 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_3 (Batch (None, 64)                256       
_________________________________________________________________
dense_4 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 65        
=================================================================
Total params: 100,673
Trainable params: 17,217
Non-trainable params: 83,456
_________________________________________________________________
Best model will be saved in  optional3_LSTM.h5
Train on 10476 samples, validate on 1165 samples
Epoch 1/100
 - 19s - loss: 0.5382 - acc: 0.7238 - val_loss: 0.5778 - val_acc: 0.6996

Epoch 00001: val_acc improved from -inf to 0.69957, saving model to optional3_LSTM.h5
Epoch 2/100
 - 18s - loss: 0.4473 - acc: 0.7771 - val_loss: 0.5208 - val_acc: 0.7391

Epoch 00002: val_acc improved from 0.69957 to 0.73906, saving model to optional3_LSTM.h5
Epoch 3/100
 - 17s - loss: 0.4299 - acc: 0.7908 - val_loss: 0.5005 - val_acc: 0.7468

Epoch 00003: val_acc improved from 0.73906 to 0.74678, saving model to optional3_LSTM.h5
Epoch 4/100
 - 17s - loss: 0.4073 - acc: 0.8006 - val_loss: 0.4688 - val_acc: 0.7485

Epoch 00004: val_acc improved from 0.74678 to 0.74850, saving model to optional3_LSTM.h5
Epoch 5/100
 - 18s - loss: 0.3990 - acc: 0.8077 - val_loss: 0.4881 - val_acc: 0.7734

Epoch 00005: val_acc improved from 0.74850 to 0.77339, saving model to optional3_LSTM.h5
Epoch 6/100
 - 17s - loss: 0.3886 - acc: 0.8144 - val_loss: 0.4466 - val_acc: 0.7717

Epoch 00006: val_acc did not improve from 0.77339
Epoch 7/100
 - 18s - loss: 0.3865 - acc: 0.8158 - val_loss: 0.4499 - val_acc: 0.7871

Epoch 00007: val_acc improved from 0.77339 to 0.78712, saving model to optional3_LSTM.h5
Epoch 8/100
 - 17s - loss: 0.3771 - acc: 0.8180 - val_loss: 0.4347 - val_acc: 0.7897

Epoch 00008: val_acc improved from 0.78712 to 0.78970, saving model to optional3_LSTM.h5
Epoch 9/100
 - 17s - loss: 0.3685 - acc: 0.8275 - val_loss: 0.3956 - val_acc: 0.8000

Epoch 00009: val_acc improved from 0.78970 to 0.80000, saving model to optional3_LSTM.h5
Epoch 10/100
 - 17s - loss: 0.3675 - acc: 0.8254 - val_loss: 0.4905 - val_acc: 0.7665

Epoch 00010: val_acc did not improve from 0.80000
Epoch 11/100
 - 17s - loss: 0.3687 - acc: 0.8203 - val_loss: 0.4392 - val_acc: 0.8086

Epoch 00011: val_acc improved from 0.80000 to 0.80858, saving model to optional3_LSTM.h5
Epoch 12/100
 - 17s - loss: 0.3600 - acc: 0.8237 - val_loss: 0.3945 - val_acc: 0.8258

Epoch 00012: val_acc improved from 0.80858 to 0.82575, saving model to optional3_LSTM.h5
Epoch 13/100
 - 17s - loss: 0.3608 - acc: 0.8252 - val_loss: 0.4118 - val_acc: 0.8112

Epoch 00013: val_acc did not improve from 0.82575
Epoch 14/100
 - 17s - loss: 0.3422 - acc: 0.8376 - val_loss: 0.4485 - val_acc: 0.8017

Epoch 00014: val_acc did not improve from 0.82575
Epoch 15/100
 - 17s - loss: 0.3489 - acc: 0.8330 - val_loss: 0.3970 - val_acc: 0.8292

Epoch 00015: val_acc improved from 0.82575 to 0.82918, saving model to optional3_LSTM.h5
Epoch 16/100
 - 17s - loss: 0.3456 - acc: 0.8361 - val_loss: 0.4771 - val_acc: 0.7837

Epoch 00016: val_acc did not improve from 0.82918
Epoch 17/100
 - 17s - loss: 0.3419 - acc: 0.8373 - val_loss: 0.4212 - val_acc: 0.8146

Epoch 00017: val_acc did not improve from 0.82918
Epoch 18/100
 - 17s - loss: 0.3450 - acc: 0.8406 - val_loss: 0.3765 - val_acc: 0.8438

Epoch 00018: val_acc improved from 0.82918 to 0.84378, saving model to optional3_LSTM.h5
Epoch 19/100
 - 17s - loss: 0.3374 - acc: 0.8456 - val_loss: 0.4037 - val_acc: 0.8240

Epoch 00019: val_acc did not improve from 0.84378
Epoch 20/100
 - 17s - loss: 0.3328 - acc: 0.8461 - val_loss: 0.4778 - val_acc: 0.7871

Epoch 00020: val_acc did not improve from 0.84378
Epoch 21/100
 - 17s - loss: 0.3320 - acc: 0.8472 - val_loss: 0.4442 - val_acc: 0.8086

Epoch 00021: val_acc did not improve from 0.84378
Epoch 22/100
 - 17s - loss: 0.3311 - acc: 0.8460 - val_loss: 0.4278 - val_acc: 0.7983

Epoch 00022: val_acc did not improve from 0.84378
Epoch 23/100
 - 17s - loss: 0.3278 - acc: 0.8477 - val_loss: 0.3721 - val_acc: 0.8232

Epoch 00023: val_acc did not improve from 0.84378
Epoch 24/100
 - 17s - loss: 0.3297 - acc: 0.8442 - val_loss: 0.4104 - val_acc: 0.8258

Epoch 00024: val_acc did not improve from 0.84378
Epoch 25/100
 - 17s - loss: 0.3223 - acc: 0.8521 - val_loss: 0.4946 - val_acc: 0.7777

Epoch 00025: val_acc did not improve from 0.84378

Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 26/100
 - 17s - loss: 0.3077 - acc: 0.8579 - val_loss: 0.3917 - val_acc: 0.8258

Epoch 00026: val_acc did not improve from 0.84378
Epoch 27/100
 - 17s - loss: 0.3018 - acc: 0.8591 - val_loss: 0.3718 - val_acc: 0.8352

Epoch 00027: val_acc did not improve from 0.84378
Epoch 28/100
 - 17s - loss: 0.2997 - acc: 0.8615 - val_loss: 0.3512 - val_acc: 0.8489

Epoch 00028: val_acc improved from 0.84378 to 0.84893, saving model to optional3_LSTM.h5
Epoch 29/100
 - 17s - loss: 0.3002 - acc: 0.8622 - val_loss: 0.3605 - val_acc: 0.8352

Epoch 00029: val_acc did not improve from 0.84893
Epoch 30/100
 - 17s - loss: 0.3028 - acc: 0.8573 - val_loss: 0.3417 - val_acc: 0.8644

Epoch 00030: val_acc improved from 0.84893 to 0.86438, saving model to optional3_LSTM.h5
Epoch 31/100
 - 17s - loss: 0.2918 - acc: 0.8665 - val_loss: 0.4000 - val_acc: 0.8240

Epoch 00031: val_acc did not improve from 0.86438
Epoch 32/100
 - 17s - loss: 0.2935 - acc: 0.8682 - val_loss: 0.3423 - val_acc: 0.8455

Epoch 00032: val_acc did not improve from 0.86438
Epoch 33/100
 - 17s - loss: 0.2965 - acc: 0.8642 - val_loss: 0.3465 - val_acc: 0.8524

Epoch 00033: val_acc did not improve from 0.86438
Epoch 34/100
 - 17s - loss: 0.2877 - acc: 0.8672 - val_loss: 0.3780 - val_acc: 0.8481

Epoch 00034: val_acc did not improve from 0.86438
Epoch 35/100
 - 17s - loss: 0.2901 - acc: 0.8652 - val_loss: 0.3801 - val_acc: 0.8309

Epoch 00035: val_acc did not improve from 0.86438
Epoch 36/100
 - 17s - loss: 0.2896 - acc: 0.8684 - val_loss: 0.3567 - val_acc: 0.8515

Epoch 00036: val_acc did not improve from 0.86438
Epoch 37/100
 - 17s - loss: 0.2890 - acc: 0.8645 - val_loss: 0.3524 - val_acc: 0.8429

Epoch 00037: val_acc did not improve from 0.86438

Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 38/100
 - 17s - loss: 0.2797 - acc: 0.8735 - val_loss: 0.3510 - val_acc: 0.8515

Epoch 00038: val_acc did not improve from 0.86438
Epoch 39/100
 - 17s - loss: 0.2745 - acc: 0.8754 - val_loss: 0.3338 - val_acc: 0.8652

Epoch 00039: val_acc improved from 0.86438 to 0.86524, saving model to optional3_LSTM.h5
Epoch 40/100
 - 17s - loss: 0.2761 - acc: 0.8748 - val_loss: 0.3228 - val_acc: 0.8644

Epoch 00040: val_acc did not improve from 0.86524
Epoch 41/100
 - 17s - loss: 0.2742 - acc: 0.8752 - val_loss: 0.3439 - val_acc: 0.8558

Epoch 00041: val_acc did not improve from 0.86524
Epoch 42/100
 - 17s - loss: 0.2705 - acc: 0.8771 - val_loss: 0.3528 - val_acc: 0.8541

Epoch 00042: val_acc did not improve from 0.86524
Epoch 43/100
 - 17s - loss: 0.2747 - acc: 0.8735 - val_loss: 0.3526 - val_acc: 0.8489

Epoch 00043: val_acc did not improve from 0.86524
Epoch 44/100
 - 17s - loss: 0.2739 - acc: 0.8757 - val_loss: 0.3496 - val_acc: 0.8515

Epoch 00044: val_acc did not improve from 0.86524
Epoch 45/100
 - 17s - loss: 0.2698 - acc: 0.8780 - val_loss: 0.3541 - val_acc: 0.8421

Epoch 00045: val_acc did not improve from 0.86524
Epoch 46/100
 - 17s - loss: 0.2711 - acc: 0.8753 - val_loss: 0.3489 - val_acc: 0.8532

Epoch 00046: val_acc did not improve from 0.86524

Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 47/100
 - 17s - loss: 0.2622 - acc: 0.8796 - val_loss: 0.3334 - val_acc: 0.8644

Epoch 00047: val_acc did not improve from 0.86524
Epoch 48/100
 - 17s - loss: 0.2610 - acc: 0.8801 - val_loss: 0.3332 - val_acc: 0.8644

Epoch 00048: val_acc did not improve from 0.86524
Epoch 49/100
 - 17s - loss: 0.2639 - acc: 0.8785 - val_loss: 0.3289 - val_acc: 0.8644

Epoch 00049: val_acc did not improve from 0.86524
Epoch 00049: early stopping
Test accuracy score with frozen first layers : 0.8505668155273102 
Model Summary after unfreezing layers
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 187, 64)           16896     
_________________________________________________________________
lstm_2 (LSTM)                (None, 187, 64)           33024     
_________________________________________________________________
lstm_3 (LSTM)                (None, 64)                33024     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_1 (Batch (None, 64)                256       
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
dense_3 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_3 (Batch (None, 64)                256       
_________________________________________________________________
dense_4 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 65        
=================================================================
Total params: 100,673
Trainable params: 100,161
Non-trainable params: 512
_________________________________________________________________
Train on 10476 samples, validate on 1165 samples
Epoch 1/100
 - 89s - loss: 0.5037 - acc: 0.7637 - val_loss: 0.5515 - val_acc: 0.7322

Epoch 00001: val_acc did not improve from 0.86524
Epoch 2/100
 - 85s - loss: 0.4048 - acc: 0.8190 - val_loss: 0.4016 - val_acc: 0.8129

Epoch 00002: val_acc did not improve from 0.86524
Epoch 3/100
 - 85s - loss: 0.3437 - acc: 0.8525 - val_loss: 0.3609 - val_acc: 0.8378

Epoch 00003: val_acc did not improve from 0.86524
Epoch 4/100
 - 86s - loss: 0.3091 - acc: 0.8675 - val_loss: 0.2915 - val_acc: 0.8867

Epoch 00004: val_acc improved from 0.86524 to 0.88670, saving model to optional3_LSTM.h5
Epoch 5/100
 - 86s - loss: 0.3209 - acc: 0.8610 - val_loss: 0.3268 - val_acc: 0.8481

Epoch 00005: val_acc did not improve from 0.88670
Epoch 6/100
 - 85s - loss: 0.2654 - acc: 0.8872 - val_loss: 0.2884 - val_acc: 0.8747

Epoch 00006: val_acc did not improve from 0.88670
Epoch 7/100
 - 86s - loss: 0.2301 - acc: 0.9053 - val_loss: 0.2333 - val_acc: 0.8996

Epoch 00007: val_acc improved from 0.88670 to 0.89957, saving model to optional3_LSTM.h5
Epoch 8/100
 - 85s - loss: 0.2093 - acc: 0.9141 - val_loss: 0.2328 - val_acc: 0.9039

Epoch 00008: val_acc improved from 0.89957 to 0.90386, saving model to optional3_LSTM.h5
Epoch 9/100
 - 85s - loss: 0.1979 - acc: 0.9221 - val_loss: 0.2184 - val_acc: 0.9039

Epoch 00009: val_acc did not improve from 0.90386
Epoch 10/100
 - 85s - loss: 0.1846 - acc: 0.9279 - val_loss: 0.1938 - val_acc: 0.9236

Epoch 00010: val_acc improved from 0.90386 to 0.92361, saving model to optional3_LSTM.h5
Epoch 11/100
 - 85s - loss: 0.1793 - acc: 0.9266 - val_loss: 0.2262 - val_acc: 0.9107

Epoch 00011: val_acc did not improve from 0.92361
Epoch 12/100
 - 84s - loss: 0.1684 - acc: 0.9337 - val_loss: 0.1818 - val_acc: 0.9227

Epoch 00012: val_acc did not improve from 0.92361
Epoch 13/100
 - 84s - loss: 0.1569 - acc: 0.9380 - val_loss: 0.2014 - val_acc: 0.9227

Epoch 00013: val_acc did not improve from 0.92361
Epoch 14/100
 - 84s - loss: 0.1612 - acc: 0.9373 - val_loss: 0.1929 - val_acc: 0.9133

Epoch 00014: val_acc did not improve from 0.92361
Epoch 15/100
 - 83s - loss: 0.1450 - acc: 0.9434 - val_loss: 0.2064 - val_acc: 0.9116

Epoch 00015: val_acc did not improve from 0.92361
Epoch 16/100
 - 84s - loss: 0.1462 - acc: 0.9455 - val_loss: 0.1741 - val_acc: 0.9270

Epoch 00016: val_acc improved from 0.92361 to 0.92704, saving model to optional3_LSTM.h5
Epoch 17/100
 - 84s - loss: 0.1340 - acc: 0.9458 - val_loss: 0.1838 - val_acc: 0.9270

Epoch 00017: val_acc did not improve from 0.92704
Epoch 18/100
 - 83s - loss: 0.1312 - acc: 0.9489 - val_loss: 0.1660 - val_acc: 0.9288

Epoch 00018: val_acc improved from 0.92704 to 0.92876, saving model to optional3_LSTM.h5
Epoch 19/100
 - 84s - loss: 0.1272 - acc: 0.9519 - val_loss: 0.1985 - val_acc: 0.9159

Epoch 00019: val_acc did not improve from 0.92876
Epoch 20/100
 - 84s - loss: 0.1288 - acc: 0.9515 - val_loss: 0.1801 - val_acc: 0.9193

Epoch 00020: val_acc did not improve from 0.92876
Epoch 21/100
 - 84s - loss: 0.1177 - acc: 0.9557 - val_loss: 0.1438 - val_acc: 0.9365

Epoch 00021: val_acc improved from 0.92876 to 0.93648, saving model to optional3_LSTM.h5
Epoch 22/100
 - 84s - loss: 0.1164 - acc: 0.9567 - val_loss: 0.1966 - val_acc: 0.9176

Epoch 00022: val_acc did not improve from 0.93648
Epoch 23/100
 - 85s - loss: 0.1090 - acc: 0.9605 - val_loss: 0.1449 - val_acc: 0.9356

Epoch 00023: val_acc did not improve from 0.93648
Epoch 24/100
 - 85s - loss: 0.1048 - acc: 0.9611 - val_loss: 0.1451 - val_acc: 0.9425

Epoch 00024: val_acc improved from 0.93648 to 0.94249, saving model to optional3_LSTM.h5
Epoch 25/100
 - 85s - loss: 0.1073 - acc: 0.9592 - val_loss: 0.1552 - val_acc: 0.9425

Epoch 00025: val_acc did not improve from 0.94249
Epoch 26/100
 - 85s - loss: 0.1031 - acc: 0.9610 - val_loss: 0.1448 - val_acc: 0.9468

Epoch 00026: val_acc improved from 0.94249 to 0.94678, saving model to optional3_LSTM.h5
Epoch 27/100
 - 86s - loss: 0.0996 - acc: 0.9644 - val_loss: 0.1718 - val_acc: 0.9365

Epoch 00027: val_acc did not improve from 0.94678
Epoch 28/100
 - 85s - loss: 0.1003 - acc: 0.9634 - val_loss: 0.1753 - val_acc: 0.9348

Epoch 00028: val_acc did not improve from 0.94678
Epoch 29/100
 - 85s - loss: 0.1003 - acc: 0.9624 - val_loss: 0.1292 - val_acc: 0.9476

Epoch 00029: val_acc improved from 0.94678 to 0.94764, saving model to optional3_LSTM.h5
Epoch 30/100
 - 85s - loss: 0.0926 - acc: 0.9664 - val_loss: 0.1389 - val_acc: 0.9485

Epoch 00030: val_acc improved from 0.94764 to 0.94850, saving model to optional3_LSTM.h5
Epoch 31/100
 - 84s - loss: 0.0907 - acc: 0.9661 - val_loss: 0.1390 - val_acc: 0.9425

Epoch 00031: val_acc did not improve from 0.94850
Epoch 32/100
 - 84s - loss: 0.1010 - acc: 0.9624 - val_loss: 0.1467 - val_acc: 0.9476

Epoch 00032: val_acc did not improve from 0.94850
Epoch 33/100
 - 84s - loss: 0.0899 - acc: 0.9684 - val_loss: 0.1256 - val_acc: 0.9476

Epoch 00033: val_acc did not improve from 0.94850
Epoch 34/100
 - 84s - loss: 0.0892 - acc: 0.9676 - val_loss: 0.1502 - val_acc: 0.9408

Epoch 00034: val_acc did not improve from 0.94850
Epoch 35/100
 - 85s - loss: 0.0826 - acc: 0.9707 - val_loss: 0.1262 - val_acc: 0.9502

Epoch 00035: val_acc improved from 0.94850 to 0.95021, saving model to optional3_LSTM.h5
Epoch 36/100
 - 84s - loss: 0.0819 - acc: 0.9713 - val_loss: 0.2000 - val_acc: 0.9279

Epoch 00036: val_acc did not improve from 0.95021
Epoch 37/100
 - 84s - loss: 0.0772 - acc: 0.9723 - val_loss: 0.1203 - val_acc: 0.9545

Epoch 00037: val_acc improved from 0.95021 to 0.95451, saving model to optional3_LSTM.h5
Epoch 38/100
 - 84s - loss: 0.0846 - acc: 0.9713 - val_loss: 0.1308 - val_acc: 0.9519

Epoch 00038: val_acc did not improve from 0.95451
Epoch 39/100
 - 84s - loss: 0.0870 - acc: 0.9682 - val_loss: 0.1356 - val_acc: 0.9511

Epoch 00039: val_acc did not improve from 0.95451
Epoch 40/100
 - 84s - loss: 0.0785 - acc: 0.9717 - val_loss: 0.1309 - val_acc: 0.9511

Epoch 00040: val_acc did not improve from 0.95451
Epoch 41/100
 - 84s - loss: 0.0728 - acc: 0.9734 - val_loss: 0.1337 - val_acc: 0.9476

Epoch 00041: val_acc did not improve from 0.95451
Epoch 42/100
 - 84s - loss: 0.0863 - acc: 0.9673 - val_loss: 0.1237 - val_acc: 0.9545

Epoch 00042: val_acc did not improve from 0.95451
Epoch 43/100
 - 84s - loss: 0.0700 - acc: 0.9749 - val_loss: 0.1793 - val_acc: 0.9322

Epoch 00043: val_acc did not improve from 0.95451
Epoch 44/100
 - 84s - loss: 0.1103 - acc: 0.9589 - val_loss: 0.1916 - val_acc: 0.9296

Epoch 00044: val_acc did not improve from 0.95451

Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 45/100
 - 84s - loss: 0.0917 - acc: 0.9632 - val_loss: 0.1232 - val_acc: 0.9519

Epoch 00045: val_acc did not improve from 0.95451
Epoch 46/100
 - 87s - loss: 0.0827 - acc: 0.9673 - val_loss: 0.1240 - val_acc: 0.9528

Epoch 00046: val_acc did not improve from 0.95451
Epoch 47/100
 - 85s - loss: 0.0846 - acc: 0.9673 - val_loss: 0.1176 - val_acc: 0.9579

Epoch 00047: val_acc improved from 0.95451 to 0.95794, saving model to optional3_LSTM.h5
Epoch 48/100
 - 85s - loss: 0.0735 - acc: 0.9720 - val_loss: 0.1193 - val_acc: 0.9554

Epoch 00048: val_acc did not improve from 0.95794
Epoch 49/100
 - 85s - loss: 0.0713 - acc: 0.9737 - val_loss: 0.1004 - val_acc: 0.9605

Epoch 00049: val_acc improved from 0.95794 to 0.96052, saving model to optional3_LSTM.h5
Epoch 50/100
 - 85s - loss: 0.0642 - acc: 0.9770 - val_loss: 0.0980 - val_acc: 0.9639

Epoch 00050: val_acc improved from 0.96052 to 0.96395, saving model to optional3_LSTM.h5
Epoch 51/100
 - 85s - loss: 0.0634 - acc: 0.9772 - val_loss: 0.1069 - val_acc: 0.9588

Epoch 00051: val_acc did not improve from 0.96395
Epoch 52/100
 - 85s - loss: 0.0603 - acc: 0.9781 - val_loss: 0.0990 - val_acc: 0.9614

Epoch 00052: val_acc did not improve from 0.96395
Epoch 53/100
 - 85s - loss: 0.0642 - acc: 0.9769 - val_loss: 0.1043 - val_acc: 0.9588

Epoch 00053: val_acc did not improve from 0.96395
Epoch 54/100
 - 84s - loss: 0.0660 - acc: 0.9763 - val_loss: 0.1074 - val_acc: 0.9579

Epoch 00054: val_acc did not improve from 0.96395
Epoch 55/100
 - 84s - loss: 0.0612 - acc: 0.9766 - val_loss: 0.1263 - val_acc: 0.9459

Epoch 00055: val_acc did not improve from 0.96395
Epoch 56/100
 - 82s - loss: 0.0588 - acc: 0.9794 - val_loss: 0.1097 - val_acc: 0.9571

Epoch 00056: val_acc did not improve from 0.96395
Epoch 57/100
 - 82s - loss: 0.0484 - acc: 0.9828 - val_loss: 0.0967 - val_acc: 0.9648

Epoch 00057: val_acc improved from 0.96395 to 0.96481, saving model to optional3_LSTM.h5
Epoch 58/100
 - 83s - loss: 0.0518 - acc: 0.9810 - val_loss: 0.1122 - val_acc: 0.9597

Epoch 00058: val_acc did not improve from 0.96481
Epoch 59/100
 - 83s - loss: 0.0561 - acc: 0.9811 - val_loss: 0.1120 - val_acc: 0.9614

Epoch 00059: val_acc did not improve from 0.96481
Epoch 60/100
 - 83s - loss: 0.0529 - acc: 0.9813 - val_loss: 0.1036 - val_acc: 0.9631

Epoch 00060: val_acc did not improve from 0.96481
Epoch 61/100
 - 83s - loss: 0.0508 - acc: 0.9819 - val_loss: 0.0967 - val_acc: 0.9648

Epoch 00061: val_acc did not improve from 0.96481
Epoch 62/100
 - 81s - loss: 0.0474 - acc: 0.9821 - val_loss: 0.0992 - val_acc: 0.9614

Epoch 00062: val_acc did not improve from 0.96481
Epoch 63/100
 - 83s - loss: 0.0532 - acc: 0.9815 - val_loss: 0.1026 - val_acc: 0.9588

Epoch 00063: val_acc did not improve from 0.96481
Epoch 64/100
 - 83s - loss: 0.0490 - acc: 0.9829 - val_loss: 0.1124 - val_acc: 0.9597

Epoch 00064: val_acc did not improve from 0.96481

Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
Epoch 65/100
 - 83s - loss: 0.0399 - acc: 0.9860 - val_loss: 0.0974 - val_acc: 0.9648

Epoch 00065: val_acc did not improve from 0.96481
Epoch 66/100
 - 83s - loss: 0.0411 - acc: 0.9854 - val_loss: 0.1015 - val_acc: 0.9639

Epoch 00066: val_acc did not improve from 0.96481
Epoch 67/100
 - 84s - loss: 0.0375 - acc: 0.9877 - val_loss: 0.1010 - val_acc: 0.9639
Using TensorFlow backend.

Epoch 00067: val_acc did not improve from 0.96481
Epoch 00067: early stopping
Test accuracy score after unfreezing and training whole model: 0.9759532806595672 
