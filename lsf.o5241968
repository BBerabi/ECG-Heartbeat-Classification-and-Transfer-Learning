Sender: LSF System <lsfadmin@lo-s4-014>
Subject: Job 5241968: <python optionals/optional3/optional3.py --model GRU> in cluster <leonhard> Done

Job <python optionals/optional3/optional3.py --model GRU> was submitted from host <lo-login-01> by user <bberabi> in cluster <leonhard> at Tue Mar 17 03:31:14 2020
Job was executed on host(s) <2*lo-s4-014>, in queue <normal.24h>, as user <bberabi> in cluster <leonhard> at Tue Mar 17 03:31:36 2020
</cluster/home/bberabi> was used as the home directory.
</cluster/home/bberabi/mlfhc> was used as the working directory.
Started at Tue Mar 17 03:31:36 2020
Terminated at Tue Mar 17 04:46:13 2020
Results reported at Tue Mar 17 04:46:13 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python optionals/optional3/optional3.py --model GRU
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   14739.20 sec.
    Max Memory :                                 1472 MB
    Average Memory :                             1351.02 MB
    Total Requested Memory :                     4000.00 MB
    Delta Memory :                               2528.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   4502 sec.
    Turnaround time :                            4499 sec.

The output (if any) follows:

2020-03-17 03:31:46.234824: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-03-17 03:31:46.245128: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199845000 Hz
2020-03-17 03:31:46.245510: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x38ede90 executing computations on platform Host. Devices:
2020-03-17 03:31:46.245544: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
----------------------------------------------
Loading Model : /cluster/home/bberabi/mlfhc/models/gru/best_model_GRU_mitbih_9817.h5
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_1 (GRU)                  (None, 187, 64)           12672     
_________________________________________________________________
gru_2 (GRU)                  (None, 187, 64)           24768     
_________________________________________________________________
gru_3 (GRU)                  (None, 64)                24768     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 325       
=================================================================
Total params: 70,853
Trainable params: 70,853
Non-trainable params: 0
_________________________________________________________________
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_1 (GRU)                  (None, 187, 64)           12672     
_________________________________________________________________
gru_2 (GRU)                  (None, 187, 64)           24768     
_________________________________________________________________
gru_3 (GRU)                  (None, 64)                24768     
=================================================================
Total params: 62,208
Trainable params: 62,208
Non-trainable params: 0
_________________________________________________________________
Model Summary after adding fc layers and freezing layers from base model
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_1 (GRU)                  (None, 187, 64)           12672     
_________________________________________________________________
gru_2 (GRU)                  (None, 187, 64)           24768     
_________________________________________________________________
gru_3 (GRU)                  (None, 64)                24768     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_1 (Batch (None, 64)                256       
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
dense_3 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_3 (Batch (None, 64)                256       
_________________________________________________________________
dense_4 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 65        
=================================================================
Total params: 79,937
Trainable params: 17,217
Non-trainable params: 62,720
_________________________________________________________________
Best model will be saved in  optional3_GRU.h5
Train on 10476 samples, validate on 1165 samples
Epoch 1/100
 - 17s - loss: 0.4842 - acc: 0.7649 - val_loss: 0.5411 - val_acc: 0.7021

Epoch 00001: val_acc improved from -inf to 0.70215, saving model to optional3_GRU.h5
Epoch 2/100
 - 15s - loss: 0.3555 - acc: 0.8387 - val_loss: 0.5450 - val_acc: 0.7253

Epoch 00002: val_acc improved from 0.70215 to 0.72532, saving model to optional3_GRU.h5
Epoch 3/100
 - 16s - loss: 0.3235 - acc: 0.8557 - val_loss: 0.4428 - val_acc: 0.7923

Epoch 00003: val_acc improved from 0.72532 to 0.79227, saving model to optional3_GRU.h5
Epoch 4/100
 - 15s - loss: 0.2992 - acc: 0.8699 - val_loss: 0.3606 - val_acc: 0.8395

Epoch 00004: val_acc improved from 0.79227 to 0.83948, saving model to optional3_GRU.h5
Epoch 5/100
 - 16s - loss: 0.2799 - acc: 0.8809 - val_loss: 0.3900 - val_acc: 0.8180

Epoch 00005: val_acc did not improve from 0.83948
Epoch 6/100
 - 16s - loss: 0.2734 - acc: 0.8806 - val_loss: 0.3735 - val_acc: 0.8386

Epoch 00006: val_acc did not improve from 0.83948
Epoch 7/100
 - 16s - loss: 0.2568 - acc: 0.8906 - val_loss: 0.3643 - val_acc: 0.8489

Epoch 00007: val_acc improved from 0.83948 to 0.84893, saving model to optional3_GRU.h5
Epoch 8/100
 - 16s - loss: 0.2493 - acc: 0.8918 - val_loss: 0.3555 - val_acc: 0.8395

Epoch 00008: val_acc did not improve from 0.84893
Epoch 9/100
 - 16s - loss: 0.2403 - acc: 0.8926 - val_loss: 0.3534 - val_acc: 0.8541

Epoch 00009: val_acc improved from 0.84893 to 0.85408, saving model to optional3_GRU.h5
Epoch 10/100
 - 16s - loss: 0.2359 - acc: 0.8980 - val_loss: 0.3634 - val_acc: 0.8532

Epoch 00010: val_acc did not improve from 0.85408
Epoch 11/100
 - 16s - loss: 0.2286 - acc: 0.9037 - val_loss: 0.3184 - val_acc: 0.8730

Epoch 00011: val_acc improved from 0.85408 to 0.87296, saving model to optional3_GRU.h5
Epoch 12/100
 - 16s - loss: 0.2235 - acc: 0.9070 - val_loss: 0.3382 - val_acc: 0.8592

Epoch 00012: val_acc did not improve from 0.87296
Epoch 13/100
 - 16s - loss: 0.2164 - acc: 0.9076 - val_loss: 0.3167 - val_acc: 0.8601

Epoch 00013: val_acc did not improve from 0.87296
Epoch 14/100
 - 16s - loss: 0.2111 - acc: 0.9120 - val_loss: 0.3252 - val_acc: 0.8781

Epoch 00014: val_acc improved from 0.87296 to 0.87811, saving model to optional3_GRU.h5
Epoch 15/100
 - 16s - loss: 0.2049 - acc: 0.9130 - val_loss: 0.3370 - val_acc: 0.8601

Epoch 00015: val_acc did not improve from 0.87811
Epoch 16/100
 - 15s - loss: 0.2032 - acc: 0.9160 - val_loss: 0.3216 - val_acc: 0.8687

Epoch 00016: val_acc did not improve from 0.87811
Epoch 17/100
 - 16s - loss: 0.2018 - acc: 0.9137 - val_loss: 0.3103 - val_acc: 0.8687

Epoch 00017: val_acc did not improve from 0.87811
Epoch 18/100
 - 16s - loss: 0.1946 - acc: 0.9201 - val_loss: 0.3405 - val_acc: 0.8575

Epoch 00018: val_acc did not improve from 0.87811
Epoch 19/100
 - 16s - loss: 0.1893 - acc: 0.9215 - val_loss: 0.3260 - val_acc: 0.8670

Epoch 00019: val_acc did not improve from 0.87811
Epoch 20/100
 - 16s - loss: 0.1842 - acc: 0.9218 - val_loss: 0.3662 - val_acc: 0.8549

Epoch 00020: val_acc did not improve from 0.87811
Epoch 21/100
 - 16s - loss: 0.1885 - acc: 0.9222 - val_loss: 0.3308 - val_acc: 0.8661

Epoch 00021: val_acc did not improve from 0.87811

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 22/100
 - 16s - loss: 0.1615 - acc: 0.9317 - val_loss: 0.3233 - val_acc: 0.8798

Epoch 00022: val_acc improved from 0.87811 to 0.87983, saving model to optional3_GRU.h5
Epoch 23/100
 - 15s - loss: 0.1488 - acc: 0.9382 - val_loss: 0.3079 - val_acc: 0.8841

Epoch 00023: val_acc improved from 0.87983 to 0.88412, saving model to optional3_GRU.h5
Epoch 24/100
 - 15s - loss: 0.1516 - acc: 0.9386 - val_loss: 0.3413 - val_acc: 0.8755

Epoch 00024: val_acc did not improve from 0.88412
Epoch 25/100
 - 16s - loss: 0.1477 - acc: 0.9417 - val_loss: 0.3024 - val_acc: 0.8781

Epoch 00025: val_acc did not improve from 0.88412
Epoch 26/100
 - 16s - loss: 0.1446 - acc: 0.9401 - val_loss: 0.3083 - val_acc: 0.8815

Epoch 00026: val_acc did not improve from 0.88412
Epoch 27/100
 - 16s - loss: 0.1378 - acc: 0.9428 - val_loss: 0.3077 - val_acc: 0.8807

Epoch 00027: val_acc did not improve from 0.88412
Epoch 28/100
 - 16s - loss: 0.1420 - acc: 0.9447 - val_loss: 0.3026 - val_acc: 0.8876

Epoch 00028: val_acc improved from 0.88412 to 0.88755, saving model to optional3_GRU.h5
Epoch 29/100
 - 15s - loss: 0.1390 - acc: 0.9422 - val_loss: 0.3078 - val_acc: 0.8790

Epoch 00029: val_acc did not improve from 0.88755
Epoch 30/100
 - 16s - loss: 0.1376 - acc: 0.9443 - val_loss: 0.3160 - val_acc: 0.8910

Epoch 00030: val_acc improved from 0.88755 to 0.89099, saving model to optional3_GRU.h5
Epoch 31/100
 - 16s - loss: 0.1394 - acc: 0.9426 - val_loss: 0.3069 - val_acc: 0.8807

Epoch 00031: val_acc did not improve from 0.89099
Epoch 32/100
 - 16s - loss: 0.1331 - acc: 0.9450 - val_loss: 0.3110 - val_acc: 0.8781

Epoch 00032: val_acc did not improve from 0.89099
Epoch 33/100
 - 16s - loss: 0.1340 - acc: 0.9475 - val_loss: 0.3287 - val_acc: 0.8807

Epoch 00033: val_acc did not improve from 0.89099
Epoch 34/100
 - 15s - loss: 0.1284 - acc: 0.9502 - val_loss: 0.3098 - val_acc: 0.8815

Epoch 00034: val_acc did not improve from 0.89099
Epoch 35/100
 - 16s - loss: 0.1247 - acc: 0.9496 - val_loss: 0.3116 - val_acc: 0.8773

Epoch 00035: val_acc did not improve from 0.89099
Epoch 36/100
 - 16s - loss: 0.1242 - acc: 0.9485 - val_loss: 0.3188 - val_acc: 0.8798

Epoch 00036: val_acc did not improve from 0.89099
Epoch 37/100
 - 16s - loss: 0.1246 - acc: 0.9502 - val_loss: 0.3320 - val_acc: 0.8850

Epoch 00037: val_acc did not improve from 0.89099

Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 38/100
 - 16s - loss: 0.1096 - acc: 0.9567 - val_loss: 0.3057 - val_acc: 0.8893

Epoch 00038: val_acc did not improve from 0.89099
Epoch 39/100
 - 16s - loss: 0.1116 - acc: 0.9550 - val_loss: 0.2974 - val_acc: 0.8953

Epoch 00039: val_acc improved from 0.89099 to 0.89528, saving model to optional3_GRU.h5
Epoch 40/100
 - 16s - loss: 0.1069 - acc: 0.9571 - val_loss: 0.2957 - val_acc: 0.8953

Epoch 00040: val_acc did not improve from 0.89528
Epoch 41/100
 - 16s - loss: 0.1029 - acc: 0.9601 - val_loss: 0.2980 - val_acc: 0.8910

Epoch 00041: val_acc did not improve from 0.89528
Epoch 42/100
 - 16s - loss: 0.1093 - acc: 0.9566 - val_loss: 0.2989 - val_acc: 0.8884

Epoch 00042: val_acc did not improve from 0.89528
Epoch 43/100
 - 15s - loss: 0.1023 - acc: 0.9592 - val_loss: 0.2989 - val_acc: 0.8918

Epoch 00043: val_acc did not improve from 0.89528
Epoch 44/100
 - 16s - loss: 0.0992 - acc: 0.9611 - val_loss: 0.3007 - val_acc: 0.8910

Epoch 00044: val_acc did not improve from 0.89528
Epoch 45/100
 - 15s - loss: 0.0991 - acc: 0.9603 - val_loss: 0.3096 - val_acc: 0.8893

Epoch 00045: val_acc did not improve from 0.89528
Epoch 46/100
 - 16s - loss: 0.1022 - acc: 0.9593 - val_loss: 0.3314 - val_acc: 0.8841

Epoch 00046: val_acc did not improve from 0.89528

Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 47/100
 - 16s - loss: 0.0942 - acc: 0.9644 - val_loss: 0.2974 - val_acc: 0.8996

Epoch 00047: val_acc improved from 0.89528 to 0.89957, saving model to optional3_GRU.h5
Epoch 48/100
 - 16s - loss: 0.0922 - acc: 0.9632 - val_loss: 0.3040 - val_acc: 0.8910

Epoch 00048: val_acc did not improve from 0.89957
Epoch 49/100
 - 16s - loss: 0.0869 - acc: 0.9669 - val_loss: 0.3089 - val_acc: 0.8876

Epoch 00049: val_acc did not improve from 0.89957
Epoch 50/100
 - 15s - loss: 0.0944 - acc: 0.9633 - val_loss: 0.3054 - val_acc: 0.8944

Epoch 00050: val_acc did not improve from 0.89957
Epoch 51/100
 - 15s - loss: 0.0919 - acc: 0.9633 - val_loss: 0.3011 - val_acc: 0.8910

Epoch 00051: val_acc did not improve from 0.89957
Epoch 52/100
 - 15s - loss: 0.0934 - acc: 0.9621 - val_loss: 0.3074 - val_acc: 0.8850

Epoch 00052: val_acc did not improve from 0.89957
Epoch 53/100
 - 15s - loss: 0.0922 - acc: 0.9649 - val_loss: 0.3143 - val_acc: 0.8893

Epoch 00053: val_acc did not improve from 0.89957
Epoch 54/100
 - 16s - loss: 0.0912 - acc: 0.9639 - val_loss: 0.3021 - val_acc: 0.8927

Epoch 00054: val_acc did not improve from 0.89957

Epoch 00054: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 55/100
 - 15s - loss: 0.0908 - acc: 0.9655 - val_loss: 0.3012 - val_acc: 0.8936

Epoch 00055: val_acc did not improve from 0.89957
Epoch 56/100
 - 15s - loss: 0.0891 - acc: 0.9652 - val_loss: 0.3085 - val_acc: 0.8927

Epoch 00056: val_acc did not improve from 0.89957
Epoch 57/100
 - 15s - loss: 0.0816 - acc: 0.9692 - val_loss: 0.3094 - val_acc: 0.8953

Epoch 00057: val_acc did not improve from 0.89957
Epoch 00057: early stopping
Test accuracy score with frozen first layers : 0.9185846788045345 
Model Summary after unfreezing layers
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_1 (GRU)                  (None, 187, 64)           12672     
_________________________________________________________________
gru_2 (GRU)                  (None, 187, 64)           24768     
_________________________________________________________________
gru_3 (GRU)                  (None, 64)                24768     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_1 (Batch (None, 64)                256       
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
dense_3 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_3 (Batch (None, 64)                256       
_________________________________________________________________
dense_4 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 65        
=================================================================
Total params: 79,937
Trainable params: 79,425
Non-trainable params: 512
_________________________________________________________________
Train on 10476 samples, validate on 1165 samples
Epoch 1/100
 - 71s - loss: 0.1526 - acc: 0.9374 - val_loss: 0.2891 - val_acc: 0.9030

Epoch 00001: val_acc improved from 0.89957 to 0.90300, saving model to optional3_GRU.h5
Epoch 2/100
 - 67s - loss: 0.1028 - acc: 0.9594 - val_loss: 0.3138 - val_acc: 0.9064

Epoch 00002: val_acc improved from 0.90300 to 0.90644, saving model to optional3_GRU.h5
Epoch 3/100
 - 67s - loss: 0.0916 - acc: 0.9636 - val_loss: 0.2663 - val_acc: 0.9124

Epoch 00003: val_acc improved from 0.90644 to 0.91245, saving model to optional3_GRU.h5
Epoch 4/100
 - 67s - loss: 0.0799 - acc: 0.9702 - val_loss: 0.2828 - val_acc: 0.9090

Epoch 00004: val_acc did not improve from 0.91245
Epoch 5/100
 - 67s - loss: 0.0799 - acc: 0.9693 - val_loss: 0.2749 - val_acc: 0.9124

Epoch 00005: val_acc did not improve from 0.91245
Epoch 6/100
 - 67s - loss: 0.0728 - acc: 0.9743 - val_loss: 0.2701 - val_acc: 0.9150

Epoch 00006: val_acc improved from 0.91245 to 0.91502, saving model to optional3_GRU.h5
Epoch 7/100
 - 66s - loss: 0.0723 - acc: 0.9725 - val_loss: 0.2620 - val_acc: 0.9193

Epoch 00007: val_acc improved from 0.91502 to 0.91931, saving model to optional3_GRU.h5
Epoch 8/100
 - 67s - loss: 0.0648 - acc: 0.9758 - val_loss: 0.2555 - val_acc: 0.9176

Epoch 00008: val_acc did not improve from 0.91931
Epoch 9/100
 - 67s - loss: 0.0650 - acc: 0.9757 - val_loss: 0.2628 - val_acc: 0.9142

Epoch 00009: val_acc did not improve from 0.91931
Epoch 10/100
 - 67s - loss: 0.0644 - acc: 0.9771 - val_loss: 0.2697 - val_acc: 0.9133

Epoch 00010: val_acc did not improve from 0.91931
Epoch 11/100
 - 67s - loss: 0.0624 - acc: 0.9783 - val_loss: 0.2723 - val_acc: 0.9124

Epoch 00011: val_acc did not improve from 0.91931
Epoch 12/100
 - 66s - loss: 0.0588 - acc: 0.9783 - val_loss: 0.2632 - val_acc: 0.9219

Epoch 00012: val_acc improved from 0.91931 to 0.92189, saving model to optional3_GRU.h5
Epoch 13/100
 - 66s - loss: 0.0564 - acc: 0.9785 - val_loss: 0.2688 - val_acc: 0.9185

Epoch 00013: val_acc did not improve from 0.92189
Epoch 14/100
 - 66s - loss: 0.0533 - acc: 0.9821 - val_loss: 0.2642 - val_acc: 0.9176

Epoch 00014: val_acc did not improve from 0.92189
Epoch 15/100
 - 67s - loss: 0.0552 - acc: 0.9813 - val_loss: 0.2708 - val_acc: 0.9124

Epoch 00015: val_acc did not improve from 0.92189
Epoch 16/100
 - 67s - loss: 0.0557 - acc: 0.9796 - val_loss: 0.2598 - val_acc: 0.9245

Epoch 00016: val_acc improved from 0.92189 to 0.92446, saving model to optional3_GRU.h5
Epoch 17/100
 - 66s - loss: 0.0525 - acc: 0.9809 - val_loss: 0.2616 - val_acc: 0.9219

Epoch 00017: val_acc did not improve from 0.92446
Epoch 18/100
 - 66s - loss: 0.0477 - acc: 0.9842 - val_loss: 0.2602 - val_acc: 0.9236

Epoch 00018: val_acc did not improve from 0.92446
Epoch 19/100
 - 66s - loss: 0.0492 - acc: 0.9823 - val_loss: 0.2605 - val_acc: 0.9219

Epoch 00019: val_acc did not improve from 0.92446
Epoch 20/100
 - 66s - loss: 0.0439 - acc: 0.9858 - val_loss: 0.2561 - val_acc: 0.9253

Epoch 00020: val_acc improved from 0.92446 to 0.92532, saving model to optional3_GRU.h5
Epoch 21/100
 - 66s - loss: 0.0436 - acc: 0.9848 - val_loss: 0.2577 - val_acc: 0.9279

Epoch 00021: val_acc improved from 0.92532 to 0.92790, saving model to optional3_GRU.h5
Epoch 22/100
 - 67s - loss: 0.0467 - acc: 0.9843 - val_loss: 0.2505 - val_acc: 0.9279

Epoch 00022: val_acc did not improve from 0.92790
Epoch 23/100
 - 66s - loss: 0.0582 - acc: 0.9781 - val_loss: 0.2630 - val_acc: 0.9176

Epoch 00023: val_acc did not improve from 0.92790
Epoch 24/100
 - 67s - loss: 0.0442 - acc: 0.9839 - val_loss: 0.2482 - val_acc: 0.9288

Epoch 00024: val_acc improved from 0.92790 to 0.92876, saving model to optional3_GRU.h5
Epoch 25/100
 - 66s - loss: 0.0443 - acc: 0.9839 - val_loss: 0.2396 - val_acc: 0.9288

Epoch 00025: val_acc did not improve from 0.92876
Epoch 26/100
 - 64s - loss: 0.0439 - acc: 0.9836 - val_loss: 0.2454 - val_acc: 0.9313

Epoch 00026: val_acc improved from 0.92876 to 0.93133, saving model to optional3_GRU.h5
Epoch 27/100
 - 64s - loss: 0.0397 - acc: 0.9863 - val_loss: 0.2525 - val_acc: 0.9305

Epoch 00027: val_acc did not improve from 0.93133
Epoch 28/100
 - 64s - loss: 0.0385 - acc: 0.9874 - val_loss: 0.2490 - val_acc: 0.9279

Epoch 00028: val_acc did not improve from 0.93133
Epoch 29/100
 - 62s - loss: 0.0381 - acc: 0.9877 - val_loss: 0.2414 - val_acc: 0.9313

Epoch 00029: val_acc did not improve from 0.93133
Epoch 30/100
 - 63s - loss: 0.0354 - acc: 0.9881 - val_loss: 0.2503 - val_acc: 0.9322

Epoch 00030: val_acc improved from 0.93133 to 0.93219, saving model to optional3_GRU.h5
Epoch 31/100
 - 63s - loss: 0.0400 - acc: 0.9870 - val_loss: 0.2438 - val_acc: 0.9313

Epoch 00031: val_acc did not improve from 0.93219
Epoch 32/100
 - 62s - loss: 0.0347 - acc: 0.9884 - val_loss: 0.2450 - val_acc: 0.9313

Epoch 00032: val_acc did not improve from 0.93219
Epoch 33/100
 - 62s - loss: 0.0383 - acc: 0.9863 - val_loss: 0.2523 - val_acc: 0.9296

Epoch 00033: val_acc did not improve from 0.93219
Epoch 34/100
 - 62s - loss: 0.0340 - acc: 0.9904 - val_loss: 0.2539 - val_acc: 0.9330

Epoch 00034: val_acc improved from 0.93219 to 0.93305, saving model to optional3_GRU.h5
Epoch 35/100
 - 63s - loss: 0.0356 - acc: 0.9881 - val_loss: 0.2569 - val_acc: 0.9305

Epoch 00035: val_acc did not improve from 0.93305
Epoch 36/100
 - 64s - loss: 0.0321 - acc: 0.9893 - val_loss: 0.2639 - val_acc: 0.9270

Epoch 00036: val_acc did not improve from 0.93305
Epoch 37/100
 - 63s - loss: 0.0376 - acc: 0.9855 - val_loss: 0.2637 - val_acc: 0.9279

Epoch 00037: val_acc did not improve from 0.93305
Epoch 38/100
 - 62s - loss: 0.0380 - acc: 0.9869 - val_loss: 0.2510 - val_acc: 0.9262

Epoch 00038: val_acc did not improve from 0.93305
Epoch 39/100
 - 63s - loss: 0.0331 - acc: 0.9890 - val_loss: 0.2476 - val_acc: 0.9296

Epoch 00039: val_acc did not improve from 0.93305
Epoch 40/100
 - 63s - loss: 0.0298 - acc: 0.9890 - val_loss: 0.2477 - val_acc: 0.9313

Epoch 00040: val_acc did not improve from 0.93305
Epoch 41/100
 - 63s - loss: 0.0316 - acc: 0.9892 - val_loss: 0.2501 - val_acc: 0.9305

Epoch 00041: val_acc did not improve from 0.93305

Epoch 00041: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
Epoch 42/100
 - 64s - loss: 0.0279 - acc: 0.9912 - val_loss: 0.2439 - val_acc: 0.9339

Epoch 00042: val_acc improved from 0.93305 to 0.93391, saving model to optional3_GRU.h5
Epoch 43/100
 - 64s - loss: 0.0292 - acc: 0.9904 - val_loss: 0.2465 - val_acc: 0.9339

Epoch 00043: val_acc did not improve from 0.93391
Epoch 44/100
 - 63s - loss: 0.0252 - acc: 0.9936 - val_loss: 0.2477 - val_acc: 0.9348

Epoch 00044: val_acc improved from 0.93391 to 0.93476, saving model to optional3_GRU.h5
Epoch 45/100
 - 64s - loss: 0.0263 - acc: 0.9909 - val_loss: 0.2463 - val_acc: 0.9313

Epoch 00045: val_acc did not improve from 0.93476
Epoch 46/100
 - 64s - loss: 0.0253 - acc: 0.9925 - val_loss: 0.2452 - val_acc: 0.9339

Epoch 00046: val_acc did not improve from 0.93476
Epoch 47/100
 - 63s - loss: 0.0241 - acc: 0.9931 - val_loss: 0.2507 - val_acc: 0.9348

Epoch 00047: val_acc did not improve from 0.93476
Epoch 48/100
 - 62s - loss: 0.0228 - acc: 0.9927 - val_loss: 0.2461 - val_acc: 0.9339

Epoch 00048: val_acc did not improve from 0.93476
Epoch 49/100
 - 63s - loss: 0.0220 - acc: 0.9933 - val_loss: 0.2501 - val_acc: 0.9339

Epoch 00049: val_acc did not improve from 0.93476
Epoch 50/100
 - 63s - loss: 0.0276 - acc: 0.9905 - val_loss: 0.2497 - val_acc: 0.9339

Epoch 00050: val_acc did not improve from 0.93476
Epoch 51/100
 - 62s - loss: 0.0249 - acc: 0.9919 - val_loss: 0.2483 - val_acc: 0.9313

Epoch 00051: val_acc did not improve from 0.93476

Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
Epoch 52/100
 - 62s - loss: 0.0221 - acc: 0.9936 - val_loss: 0.2473 - val_acc: 0.9348

Epoch 00052: val_acc did not improve from 0.93476
Epoch 53/100
 - 62s - loss: 0.0225 - acc: 0.9928 - val_loss: 0.2472 - val_acc: 0.9330

Epoch 00053: val_acc did not improve from 0.93476
Epoch 54/100
 - 62s - loss: 0.0219 - acc: 0.9928 - val_loss: 0.2480 - val_acc: 0.9322
Using TensorFlow backend.

Epoch 00054: val_acc did not improve from 0.93476
Epoch 00054: early stopping
Test accuracy score after unfreezing and training whole model: 0.9440054963929921 
