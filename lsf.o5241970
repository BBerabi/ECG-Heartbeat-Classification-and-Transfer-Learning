Sender: LSF System <lsfadmin@lo-a2-062>
Subject: Job 5241970: <python optionals/optional2/optional2.py --model RNN> in cluster <leonhard> Done

Job <python optionals/optional2/optional2.py --model RNN> was submitted from host <lo-login-01> by user <bberabi> in cluster <leonhard> at Tue Mar 17 03:34:08 2020
Job was executed on host(s) <2*lo-a2-062>, in queue <normal.24h>, as user <bberabi> in cluster <leonhard> at Tue Mar 17 03:34:36 2020
</cluster/home/bberabi> was used as the home directory.
</cluster/home/bberabi/mlfhc> was used as the working directory.
Started at Tue Mar 17 03:34:36 2020
Terminated at Tue Mar 17 03:38:52 2020
Results reported at Tue Mar 17 03:38:52 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python optionals/optional2/optional2.py --model RNN
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   787.66 sec.
    Max Memory :                                 597 MB
    Average Memory :                             546.91 MB
    Total Requested Memory :                     4000.00 MB
    Delta Memory :                               3403.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   261 sec.
    Turnaround time :                            284 sec.

The output (if any) follows:

2020-03-17 03:34:43.342023: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-03-17 03:34:43.349714: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2020-03-17 03:34:43.350138: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x38665c0 executing computations on platform Host. Devices:
2020-03-17 03:34:43.350189: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
Loading Model : /cluster/home/bberabi/mlfhc/models/rnn/BestModel_RNN_mitbih_908.h5
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 187, 64)           4224      
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, 187, 64)           8256      
_________________________________________________________________
simple_rnn_3 (SimpleRNN)     (None, 64)                8256      
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 325       
=================================================================
Total params: 29,381
Trainable params: 29,381
Non-trainable params: 0
_________________________________________________________________
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 187, 64)           4224      
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, 187, 64)           8256      
_________________________________________________________________
simple_rnn_3 (SimpleRNN)     (None, 64)                8256      
=================================================================
Total params: 20,736
Trainable params: 20,736
Non-trainable params: 0
_________________________________________________________________
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 187, 64)           4224      
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, 187, 64)           8256      
_________________________________________________________________
simple_rnn_3 (SimpleRNN)     (None, 64)                8256      
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_1 (Batch (None, 64)                256       
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
dense_3 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_3 (Batch (None, 64)                256       
_________________________________________________________________
dense_4 (Dense)              (None, 64)                4160      
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 65        
=================================================================
Total params: 38,465
Trainable params: 37,953
Non-trainable params: 512
_________________________________________________________________
Best model will be saved in  optional2_RNN.h5
Train on 10476 samples, validate on 1165 samples
Epoch 1/200
 - 23s - loss: 0.6265 - acc: 0.6448 - val_loss: 0.6403 - val_acc: 0.6996

Epoch 00001: val_acc improved from -inf to 0.69957, saving model to optional2_RNN.h5
Epoch 2/200
 - 21s - loss: 0.5908 - acc: 0.7024 - val_loss: 0.7770 - val_acc: 0.6996

Epoch 00002: val_acc did not improve from 0.69957
Epoch 3/200
 - 21s - loss: 0.5814 - acc: 0.7147 - val_loss: 1.2604 - val_acc: 0.6996

Epoch 00003: val_acc did not improve from 0.69957
Epoch 4/200
 - 21s - loss: 0.5914 - acc: 0.7153 - val_loss: 2.4222 - val_acc: 0.6996

Epoch 00004: val_acc did not improve from 0.69957
Epoch 5/200
 - 21s - loss: 0.5825 - acc: 0.7209 - val_loss: 1.0166 - val_acc: 0.6996

Epoch 00005: val_acc did not improve from 0.69957
Epoch 6/200
 - 21s - loss: 0.5806 - acc: 0.7194 - val_loss: 2.0309 - val_acc: 0.6996

Epoch 00006: val_acc did not improve from 0.69957
Epoch 7/200
 - 21s - loss: 0.5692 - acc: 0.7214 - val_loss: 2.8320 - val_acc: 0.6996

Epoch 00007: val_acc did not improve from 0.69957
Epoch 8/200
 - 21s - loss: 0.5636 - acc: 0.7184 - val_loss: 2.9280 - val_acc: 0.6996

Epoch 00008: val_acc did not improve from 0.69957

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 9/200
 - 21s - loss: 0.5453 - acc: 0.7225 - val_loss: 5.0878 - val_acc: 0.6996

Epoch 00009: val_acc did not improve from 0.69957
Epoch 10/200
 - 21s - loss: 0.5409 - acc: 0.7246 - val_loss: 12.7077 - val_acc: 0.6996

Epoch 00010: val_acc did not improve from 0.69957
Epoch 11/200
 - 20s - loss: 0.5407 - acc: 0.7226 - val_loss: 8.7305 - val_acc: 0.6996
Using TensorFlow backend.

Epoch 00011: val_acc did not improve from 0.69957
Epoch 00011: early stopping
Test accuracy score : 0.7220886293369976 
